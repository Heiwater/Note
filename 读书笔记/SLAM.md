# 这是啥
这是视觉《SLAM十四讲》这本书的读书笔记，其实很早之前就被要求说是读这本书，但是没办法，懒狗是这样的。在这里就顺带的记一下自己学到到的，以及有的没的的东西好了

# 第1&2讲

## 啥是SLAM
SLAM是Simultaneous Localization and Mapping的缩写，汉语是“同时定位与地图构建”。

> 说人话就是医生捅个腔镜进去后能捅来捅去知道这个腔镜在你体内都溜达去了那里，能画个地图出来，嗯，就这样。

SLAM的目的是解决“定位”与“地图构建”，这两个问题，我们希望能够实时地、在没有先验只是的情况下进行SLAM，当用相机作为传感器的时候，要做的就是根据一张张连续运动的图像，从中推测相机的运动，以及周围环境的情况。

> 我说啥来着，就这意思。

## 相机的分类
一言以概之，分为三类：
|分类|英文|干啥的|
|:-|:-|:-|
|单目相机|Monocular|就只有一个摄像头，比较的寒酸，但是好在便宜，咱腔镜估摸着也就是这一个孤零零的的摄像头，但是往好处想，至少像素高，就是清晰|
|双目相机|Stereo|顾名思义，有俩摄像头，能根据摄像头的距离制定基线，方便判断物体的远近|
|深度相机|RGB-D|简言之多个红外光，但是相较来说要算得东西是最多的|

## 经典视觉SLAM框架
视觉SLAM模型由如下模块组成：
1. 传感器信息读取：视觉SLAM中主要是相机的信息读取和预处理，也就是给相机拍出来的图片校准，然后规整下图片格式，就是这
2. 前端视觉里程计（Visual Odometry，VO）：视觉里程计的任务是估算相邻图像间相机的运动，以及局部地图的样子。VO又成为前端（Front End）
3. 后端（非线性）优化：后端接受不同时刻视觉里程计测量的相机位姿（位置&姿态），以及回环检测的信息，对他们进行优化，的大全局一致的轨迹和地图。由于在VO之后，又称为后端（Back End）
4. 回环检测（Loop Closure Dection）：检测饶了一圈之后是否到达原来的位置。如果检测到回环，他会把信息提供给后端进行处理
5. 建图（Mapping）：根据估计的轨迹，建立与任务要求对应的地图。

## 一些术语

### 视觉里程计
视觉里程计能够通过相邻帧间的图像估计相机的运动，并恢复场景的空间结构

### 累计漂移
说人话就是转了一圈回去了，但是由于误差的存在没有检测出来，为了解决这个问题引伸出了后端优化和回环检测。

### 后端优化
在视觉SLAM中，前端了计算机视觉研究领域更为相关，比如图像的特征提取与匹配，后端则主要是滤波和非线性优化算法。

### 回环检测
根据图像间的相似性实现回环检测

### 度量地图
度量地图强调精确地表示地图中物体的位置关系，通常用稀疏（Sparse）与稠密（Dense）表示。

一些有代表性的东西叫做路标（Landmark），一张稀疏地图就是由路标组成的地图

### 拓扑地图
拓扑地图也是一个图，由节点和变组成，只考虑节点间的连通性

# 第3讲

## 实践Eigen
这里老老实实跟着人家敲了一边基础的代码，发现自己之前cmake使用上面有很多的疏漏，至少CMakeLists少打了一个s

要说些啥呢？想到啥说啥吧。

首先你的环境必须是c++ 11，不然没有库，其次引用的时候，如果不使用cmake，是需要讲`#include <Eigen/Core> & #include <Eigen/Dense>`，改为`#include <eigen3/Eigen/Core> & #include <eigen3/Eigen/Dense>`

引用完头文件之后，你就可以直接使用`Matrix`类了，简言之`Matrix<type,row,colum> my_matrix_NAME`
可以喜闻乐见的直接按名称输出了即：`cout << my_matrix_NAME(i,j)`

然后常见的功能都给你写进库里面了：
|名称|函数|功能|
|:-|:-|:-|
|转置|`.transpose()`|输出转置|
|求和|`.sum()`|输出各元素和|
|迹|`.trace()`|就是矩阵的斜对角，坐上到右下的加和|
|数乘|`number * my_matrix_name`|直接乘就可以，顺带一提，四则运算是直接加减乘除就可以的|
|逆|`.inverse()`|矩阵的逆矩阵|
|行列式|`.determinant()`|就是一开始文盲的“绝对值”，顺带一提矩阵的行列式是一个值|

别的其实还有很多，但是后面见到一个在整一个好了，问题不大


